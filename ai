@Bean
@ConditionalOnMissingBean(name = "kafkaSdkConsumerFactory")
public ConsumerFactory<String, Object> kafkaSdkConsumerFactory() {

    Map<String, Object> config = new HashMap<>();

    config.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, "SSL");
    config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, props.getBootstrapServers());
    KafkaUtil.setBrokersSsl(config, props.getSsl());

    config.put(ConsumerConfig.GROUP_ID_CONFIG, props.getGroupId());
    config.put(ConsumerConfig.CLIENT_ID_CONFIG, props.getClientId() + "-consumer");
    config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);
    config.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, props.getMaxPollIntervalMs());
    config.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, props.getMaxPollRecords());
    config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

    // ✅ Use ErrorHandlingDeserializer for BOTH key/value
    config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
            org.springframework.kafka.support.serializer.ErrorHandlingDeserializer.class);
    config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
            org.springframework.kafka.support.serializer.ErrorHandlingDeserializer.class);

    // ✅ Delegate deserializers (these are the IMPORTANT keys)
    config.put("spring.deserializer.key.delegate.class",
            org.apache.kafka.common.serialization.StringDeserializer.class.getName());

    String format = props.getMessageFormat().toLowerCase();
    switch (format) {
        case "avro" -> {
            config.put("spring.deserializer.value.delegate.class",
                    io.confluent.kafka.serializers.KafkaAvroDeserializer.class.getName());
            config.put("schema.registry.url", props.getSchemaRegistryUrl());
            config.put("specific.avro.reader", true);
            KafkaUtil.setSchemaRegistrySsl(config, props.getSsl());
        }
        case "json" -> {
            // your current JSON mode uses String value - OK for simulation
            config.put("spring.deserializer.value.delegate.class",
                    org.apache.kafka.common.serialization.StringDeserializer.class.getName());
        }
        default -> throw new IllegalArgumentException("Unsupported kafka.sdk.format: " + format);
    }

    return new DefaultKafkaConsumerFactory<>(config);
}